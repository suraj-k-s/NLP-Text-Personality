{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce29be61-2b0d-49fd-9ba4-37710ef18cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0831bfc1-adaa-46f2-b940-29fb9aab086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = pickle.load(open('log_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6899d802-abf4-4da2-b4a9-e375412b5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(data):\n",
    "    data_length=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    cleaned_text=[]\n",
    "    for sentence in tqdm(data.posts):\n",
    "        sentence=sentence.lower()\n",
    "        \n",
    "#         removing links from text data\n",
    "        sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n",
    "    \n",
    "#         removing other symbols\n",
    "        sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "    \n",
    "        \n",
    "        data_length.append(len(sentence.split()))\n",
    "        cleaned_text.append(sentence)\n",
    "    return cleaned_text,data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe7f564-d182-4aa3-a775-3d61fc055c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder=pickle.load(open(\"target_encoder.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b1dc99-41db-4c70-9792-3f371bb452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemmatizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, sentence):\n",
    "        return [self.lemmatizer.lemmatize(word) for word in sentence.split() if len(word)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b4a9e6-83e1-40b9-bd75-a53ae5568d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"vectorizer.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62524ccd-8633-4d60-aaf5-b3009aaf3ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1018.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    your time is limited  so don t waste it living...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = {'posts':\"Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma – which is living with the results of other people's thinking\"}\n",
    "x=pd.DataFrame(dd,index=[0])\n",
    "x.posts,x_length=clear_text(x)\n",
    "x.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b11460-23a0-473d-ae8c-6be93789055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_post1=vectorizer.transform(x.posts).toarray()\n",
    "train_post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1eba12-1775-4499-a2ae-bdce5cec4162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_post1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5442003a-d6d3-4261-90f1-438e979dcd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.predict(train_post1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f32e0f-d91b-4cf9-b35e-668fe4f2a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTP'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op=model_log.predict(train_post1)\n",
    "\n",
    "target_names=target_encoder.inverse_transform(op)\n",
    "target_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
